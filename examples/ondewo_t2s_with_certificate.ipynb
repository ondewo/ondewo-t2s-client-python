{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKWBIVdK_r0Z"
   },
   "source": [
    "## **Text2Speech T2S API**\n",
    "\n",
    "This tutorial uses ondewo-t2s-api to:\n",
    "\n",
    "*   List the possible pipelines that can be used for synthesizing\n",
    "*   List the possible languages that can be used in the synthesize process\n",
    "*   List the possible domains\n",
    "*   Synthesize a text to audio\n",
    "*   Synthesize a batch of texts to audios\n",
    "*   Manipulate pipelines (Create, Delete, Update, Get)\n",
    "\n",
    "\n",
    "The first step is to install and the Ondewo Text to Speech client and the requirements needed to interact with the server\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s2ePqjpJccmr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "! pwd\n",
    "! ls\n",
    "! rm -rf ondewo-t2s-client-python\n",
    "! git clone https://github.com/ondewo/ondewo-t2s-client-python.git\n",
    "! cd ondewo-t2s-client-python && git checkout tags/3.1.0 -b 3.1.0 && pip install -r requirements.txt  && git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AZCHNpJytnZ"
   },
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "! cd ondewo-t2s-client-python && python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u05mpboMICjZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import numpy\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd\n",
    "import grpc\n",
    "from ondewo.t2s import text_to_speech_pb2, text_to_speech_pb2_grpc\n",
    "from google.protobuf.json_format import ParseDict, MessageToDict, MessageToJson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqzktvBHdNHN"
   },
   "source": [
    "Afterwards, the client's objects classes need to be imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_l5Y2hqdLO1"
   },
   "outputs": [],
   "source": [
    "from ondewo.t2s import text_to_speech_pb2\n",
    "from ondewo.t2s.client.client import Client\n",
    "from ondewo.t2s.client.client_config import ClientConfig\n",
    "from ondewo.t2s.client.services.text_to_speech import Text2Speech\n",
    "from ondewo.t2s.text_to_speech_pb2 import ListT2sPipelinesRequest, Text2SpeechConfig \n",
    "from ondewo.t2s.text_to_speech_pb2 import ListT2sLanguagesRequest, ListT2sDomainsRequest\n",
    "from ondewo.t2s.text_to_speech_pb2 import T2sPipelineId, RequestConfig, SynthesizeRequest\n",
    "from ondewo.t2s.text_to_speech_pb2 import BatchSynthesizeRequest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lg990OWCtZRw"
   },
   "source": [
    "## Connect to the Text to Speech Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9Dsp0u7JE-y"
   },
   "source": [
    "The example below shows how to create a secure channel for a text to speech stub object. When setting *use_secure_channel=True*, a grpc certificate *grpc_cert* is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQ4eTNYLJY0W"
   },
   "outputs": [],
   "source": [
    "# credentials = grpc.ssl_channel_credentials(root_certificates=cert)\n",
    "\n",
    "MAX_MESSAGE_LENGTH: int = 60000000\n",
    "GRPC_HOST: str = \"\"\n",
    "GRPC_PORT: str = \"\"\n",
    "CHANNEL: str = f\"{GRPC_HOST}:{GRPC_PORT}\"\n",
    "cert=\"\"\n",
    "\n",
    "\n",
    "options = [\n",
    "    ('grpc.max_send_message_length', MAX_MESSAGE_LENGTH),\n",
    "    ('grpc.max_receive_message_length', MAX_MESSAGE_LENGTH),\n",
    "]\n",
    "\n",
    "# channel = grpc.secure_channel(CHANNEL, credentials, options=options)\n",
    "\n",
    "config: ClientConfig = ClientConfig(\n",
    "  host=GRPC_HOST,\n",
    "  port=GRPC_PORT, \n",
    "  grpc_cert=cert)\n",
    "    \n",
    "print(config)\n",
    "    \n",
    "client: Client = Client(config=config, use_secure_channel=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNqz0BBntZRy"
   },
   "source": [
    "## Get the service information\n",
    "In order to get the service information, the following method can be executed. This last will retrieve the release version of the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJwo2mjbtZR0",
    "outputId": "087bd15c-805d-4fae-dfb0-70de0a340459"
   },
   "outputs": [],
   "source": [
    "client.services.text_to_speech.get_service_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kD27LELbJjxg"
   },
   "source": [
    "## List all existing text to speech pipelines\n",
    "\n",
    "All relevant configurations of the text to speech server are defined in a text to speech pipeline. A running server can store several of such configurations at the same time, and the client can chose which one to pick when he/she sends a request to synthesize a text or batch of texts.\n",
    "\n",
    "The example below shows how to list all available pipelines by calling the *ListT2sPipelines* function, which takes a *ListT2sPipelinesRequest* as an argument and retrieves a *ListT2sPipelinesResponse*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MkgvlYO7JmX_",
    "outputId": "c08a0adf-4197-4d71-8b55-7c16495b8ac8"
   },
   "outputs": [],
   "source": [
    "pipelines = client.services.text_to_speech.list_t2s_pipelines(request=ListT2sPipelinesRequest())\n",
    "pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhaYY8x6s18d"
   },
   "source": [
    "## List all possible synthesizying languages\n",
    "\n",
    "A running server can list all possible languages fulfilling specified requirements that can be used to synthesize.\n",
    "\n",
    "The example below shows how to list all available languages by calling the *ListT2sLanguages* function, which takes a *ListT2sLanguagesRequest* as an argument and retrieves a *ListT2sLanguagesResponse*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lN6L5LhitleH",
    "outputId": "6805f43c-133c-4405-e6ad-48feaa88855e"
   },
   "outputs": [],
   "source": [
    "request = ListT2sLanguagesRequest(speaker_sexes=['female'])\n",
    "response = client.services.text_to_speech.list_t2s_languages(request=request)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wk7s6tNvusda"
   },
   "source": [
    "## List all possible domains\n",
    "\n",
    "A running server can list all possible domains fulfilling specified requirements that can be used to synthesize.\n",
    "\n",
    "The example below shows how to list all available domains by calling the *ListT2sDomains* function, which takes a *ListT2sDomainsRequest* as an argument and retrieves a *ListT2sDomainsResponse*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OAv4fX5-vIkl",
    "outputId": "4b8f2199-f916-4894-ac49-e9b878e90da3"
   },
   "outputs": [],
   "source": [
    "request = ListT2sDomainsRequest(languages=['en'])\n",
    "response = client.services.text_to_speech.list_t2s_domains(request=request)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kcutwJDLTs-"
   },
   "source": [
    "# Make a synthesize request to the server\n",
    "\n",
    "The running server offers a feature for synthesizying a text into a audio. In order to make use of it, the Synthesize method is utilized. This method will receive a SynthesizeRequest and retrieve a SynthesizeResponse.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVdvO-oxUAAR"
   },
   "source": [
    "The following pipelines were chosen to examplify.\n",
    "Linda's voice is choosen for the english voice and Alexandra's voice for german. Therefore, both pipelines need to be asked for to the stab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9V7vPlstZR5"
   },
   "outputs": [],
   "source": [
    "english_pipeline = T2sPipelineId(id='linda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SWn5NWOcUBLi"
   },
   "outputs": [],
   "source": [
    "german_pipeline = T2sPipelineId(id='alexandra')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yENiOXlfUSpg"
   },
   "source": [
    "The example below shows how to synthesize a text into an audio.\n",
    "1.   A configuration has to be created with a *RequestConfig*, specifying the desired optional parameters.\n",
    "2.   A request has to be created with a *SynthesizeRequest*, specifying the text to be synthesize and the previously created configuration.\n",
    "3.   By calling the Synthesize method with the created request, the text is synthesized with the specfified configuration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gm_phM3atZR6"
   },
   "source": [
    "The following example was created with Alexandra's voice, so as to get an english speaker pronunciation in the audio for the text synthesized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "uTEIIv8qtZR6",
    "outputId": "5a644eaa-1e7b-4708-d684-bd59bf7cbe0b"
   },
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id, \n",
    "                       length_scale = 1.0)\n",
    "request = SynthesizeRequest(text=\"Hi, this is Alexandra. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\", \n",
    "                            config=config)\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "bio = io.BytesIO(response.audio)\n",
    "audio = sf.read(bio, )\n",
    "ipd.Audio(audio[0], rate=audio[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpL5lStDtZR7"
   },
   "source": [
    "### Length scale configuration\n",
    "The attribute length_scale can be finetuned in order to speed up or slow down the audio. \n",
    "In the next example the length_scale attribute is set to 0.5 so the retrieved audio will be twice as fast as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "-jMXjjb3tZR7",
    "outputId": "0acb85e0-c9fb-4ecd-d71c-f0c504db406e"
   },
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id, \n",
    "                       length_scale = 0.5)\n",
    "request = SynthesizeRequest(text=\"Hi, this is Alexandra. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\",\n",
    "                            config=config)\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "bio = io.BytesIO(response.audio)\n",
    "audio = sf.read(bio, )\n",
    "ipd.Audio(audio[0], rate=audio[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sk8HTDMRtZR7"
   },
   "source": [
    "Next, the same attribute is being set to 2.0, therefore, the retrieved audio will be half as fast in comparison to the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "-UrYguj_L3dx",
    "outputId": "4b195c47-4a1e-4ca8-b00e-8b089c785c73"
   },
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id, \n",
    "                       length_scale = 2.0)\n",
    "request = SynthesizeRequest(text=\"Hi, this is Alexandra. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\",\n",
    "                            config=config)\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "\n",
    "bio = io.BytesIO(response.audio)\n",
    "audio = sf.read(bio, )\n",
    "ipd.Audio(audio[0], rate=audio[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_015ySStZR8"
   },
   "source": [
    "### Audio Format confguration\n",
    "\n",
    "Another attribute that can be configurated is the audio_format.\n",
    "Audio Format can the setted to:\n",
    "\n",
    "- 0 for wav\n",
    "- 1 for flac\n",
    "- 2 for caf (Core audio format)\n",
    "- 3 for mp3\n",
    "- 4 for acc (Advanced audio coding)\n",
    "- 5 for ogg\n",
    "- 6 for wma (Windows media audio)\n",
    "\n",
    "In the following example, the attribute audio_format is setted to create a wav audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "gquB0QY8tZR8",
    "outputId": "b6858170-2490-4811-dfc9-0b70bef887e0"
   },
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id, \n",
    "                       audio_format = 0)\n",
    "request = SynthesizeRequest(text=\"Hi, this is Alexandra. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\",\n",
    "                            config=config)\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "bio = io.BytesIO(response.audio)\n",
    "audio = sf.read(bio, )\n",
    "ipd.Audio(audio[0], rate=audio[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psU228XMtZR8"
   },
   "source": [
    "### Pulse Code Modulation\n",
    "\n",
    "The pcm attribute represents the number of pulses created for the audio file.\n",
    "A pcm signal is a sequence of digital audio samples containing the data providing the necessary information to reconstruct the original analog signal.\n",
    "\n",
    "- 0 for 16 (16  bits per sample)\n",
    "- 1 for 24 (24  bits per sample)\n",
    "- 2 for 32 (32  bits per sample)\n",
    "- 3 for S8\n",
    "- 4 for U8\n",
    "- 5 for Float\n",
    "- 6 for Double\n",
    "\n",
    "The number of bit per sample affects the quality and size of the retrieved file. As the number of bits per sample increase, so does the size and quality of the file.\n",
    "\n",
    "In the first example the audio file is generated with the best possible quality and in the second, with the lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "6DvuWz35tZR8",
    "outputId": "17c09d0f-8bea-4fd5-f70f-8c03fe168e5d"
   },
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id, pcm = 0)\n",
    "request = SynthesizeRequest(text=\"Hi, this is Alexandra. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\",\n",
    "                            config=config)\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "bio = io.BytesIO(response.audio)\n",
    "audio = sf.read(bio, )\n",
    "ipd.Audio(audio[0], rate=audio[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "dtdyG5oitZR9",
    "outputId": "645fdf06-ed8e-4df9-f5fa-f273e64a04cc"
   },
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id, pcm = 4)\n",
    "request = SynthesizeRequest(text=\"Hi, this is Alexandra. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\",\n",
    "                            config=config)\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "bio = io.BytesIO(response.audio)\n",
    "audio = sf.read(bio, )\n",
    "ipd.Audio(audio[0], rate=audio[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7-VTdUrtZSF"
   },
   "source": [
    "## Get Pipeline\n",
    "\n",
    "In order to get an specific pipeline configuration the GetT2sPipeline method is used. This method received a T2sPipelineId and retrieves a Text2SpeechConfig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "to73X70rtZSF"
   },
   "outputs": [],
   "source": [
    "request = T2sPipelineId(id=german_pipeline.id)\n",
    "pipeline_config = client.services.text_to_speech.get_t2s_pipeline(request=request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkpdKu4O6_b_"
   },
   "source": [
    "## Create Pipeline\n",
    "\n",
    "The server provides a method for creating new pipelines. This can be done with the function CreateT2sPipeline, which receives a Text2SpeechConfig and retrieves a T2sPipelineId."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P4yVorW47Hfd"
   },
   "outputs": [],
   "source": [
    "new_inference_config = pipeline_config.inference\n",
    "new_inference_config.composite_inference.text2mel.glow_tts.length_scale = 2\n",
    "request = Text2SpeechConfig(id='alexandra_2.0',                           # Pipeline Id\n",
    "                            description=pipeline_config.description,      # Pipeline Description \n",
    "                            active=True,                                  # Pipeline is active or not\n",
    "                            inference=new_inference_config,               # Pipeline Inference configuration\n",
    "                            normalization=pipeline_config.normalization,  # Pipeline Normalization Parameters\n",
    "                            postprocessing=pipeline_config.postprocessing)# Pipeline Postprocessing\n",
    "new_pipeline_id = client.services.text_to_speech.create_t2s_pipeline(request=request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uV0kSvYYNIfq"
   },
   "source": [
    "## Update Pipeline\n",
    "\n",
    "The server provides a method to update a pipeline called UpdateT2sPipeline, receiving a pipeline configuration.\n",
    "\n",
    "In the following example, the retrieved configuration in the previous call is modified and used to update the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txiSzQnkNPf6"
   },
   "outputs": [],
   "source": [
    "pipeline_config.inference.composite_inference.text2mel.glow_tts.length_scale = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WMVoLpbxNn1I",
    "outputId": "a37b2399-755e-459c-c953-ce989ed3e97e"
   },
   "outputs": [],
   "source": [
    "client.services.text_to_speech.update_t2s_pipeline(request=pipeline_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FP4Hsy9ctZSG"
   },
   "source": [
    "## Delete Pipeline\n",
    "\n",
    "A pipeline can be deleted with the method DeleteT2sPipeline, receiving a pipeline id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5XH8ArwBtZSG",
    "outputId": "1f154e30-a72b-46c2-9142-f70fab096f4d"
   },
   "outputs": [],
   "source": [
    "request = T2sPipelineId(id='alexandra_2.0')\n",
    "pipeline_config = client.services.text_to_speech.get_t2s_pipeline(request=request)\n",
    "client.services.text_to_speech.delete_t2s_pipeline(request=request)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ondewo_t2s_with_certificate.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
