{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKWBIVdK_r0Z"
   },
   "source": [
    "## **Text2Speech T2S API**\n",
    "\n",
    "This tutorial uses ondewo-t2s-api to:\n",
    "\n",
    "*   List the possible pipelines that can be used for synthesizing\n",
    "*   List the possible languages that can be used in the synthesize process\n",
    "*   List the possible domains\n",
    "*   Synthesize a text to audio\n",
    "*   Synthesize a batch of texts to audios\n",
    "*   Manipulate pipelines (Create, Delete, Update, Get)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "! cd .. && python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u05mpboMICjZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd\n",
    "import grpc\n",
    "from ondewo.t2s import text_to_speech_pb2, text_to_speech_pb2_grpc\n",
    "import google.protobuf.empty_pb2 as empty_pb2\n",
    "from google.protobuf.json_format import ParseDict, MessageToDict, MessageToJson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9Dsp0u7JE-y"
   },
   "source": [
    "The example below shows how to create a secure channel for a text to speech stub object. When setting use_secure_channel=True, a grpc certificate grpc_cert is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQ4eTNYLJY0W"
   },
   "outputs": [],
   "source": [
    "MAX_MESSAGE_LENGTH: int = 60000000\n",
    "GRPC_HOST: str = \"dgxstation\" #\"<ADD GRPC SERVER HERE>\"\n",
    "GRPC_PORT: str = \"50557\" #\"<ADD GRPC PORT HERE>\"\n",
    "CHANNEL: str = f\"{GRPC_HOST}:{GRPC_PORT}\"\n",
    "grpc_cert: str = None #\"<ADD CERTIFICATE HERE>\"\n",
    "credentials = grpc.ssl_channel_credentials(root_certificates=grpc_cert)\n",
    "\n",
    "options = [\n",
    "    ('grpc.max_send_message_length', MAX_MESSAGE_LENGTH),\n",
    "    ('grpc.max_receive_message_length', MAX_MESSAGE_LENGTH),\n",
    "]\n",
    "\n",
    "\n",
    "# channel = grpc.secure_channel(CHANNEL, credentials=credentials, options=options)\n",
    "channel = grpc.insecure_channel(CHANNEL, options=options)\n",
    "\n",
    "stub = text_to_speech_pb2_grpc.Text2SpeechStub(channel=channel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the service info\n",
    "In order to get the service information, the following method must be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stub.GetServiceInfo(empty_pb2.Empty())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kD27LELbJjxg"
   },
   "source": [
    "## List all existing text to speech pipelines\n",
    "\n",
    "All relevant configurations of the text to speech server are defined in a text to speech pipeline. A running server can store several of such configurations at the same time, and the client can chose which one to pick when he/she sends a request to synthesize a text or batch of texts.\n",
    "\n",
    "The example below shows how to list all available pipelines by calling the ListT2sPipelines function, which takes a ListT2sPipelinesRequest as an argument and retrieves a ListT2sPipelinesResponse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MkgvlYO7JmX_"
   },
   "outputs": [],
   "source": [
    "pipelines = stub.ListT2sPipelines(request=empty_pb2.Empty()).pipelines\n",
    "pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhaYY8x6s18d"
   },
   "source": [
    "## List all possible synthesizying languages\n",
    "\n",
    "A running server can list all possible languages fulfilling specified requirements that can be used to synthesize.\n",
    "\n",
    "The example below shows how to list all available languages by calling the ListT2sLanguages function, which takes a ListT2sLanguagesRequest as an argument and retrieves a ListT2sLanguagesResponse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lN6L5LhitleH"
   },
   "outputs": [],
   "source": [
    "request = text_to_speech_pb2.ListT2sLanguagesRequest(speaker_sexes=['female'])\n",
    "response = stub.ListT2sLanguages(request=request)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wk7s6tNvusda"
   },
   "source": [
    "## List all possible domains\n",
    "\n",
    "A running server can list all possible domains fulfilling specified requirements that can be used to synthesize.\n",
    "\n",
    "The example below shows how to list all available domains by calling the ListT2sDomains function, which takes a ListT2sDomainsRequest as an argument and retrieves a ListT2sDomainsResponse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OAv4fX5-vIkl"
   },
   "outputs": [],
   "source": [
    "request = text_to_speech_pb2.ListT2sDomainsRequest(languages=['en'])\n",
    "response = stub.ListT2sDomains(request=request)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kcutwJDLTs-"
   },
   "source": [
    "# Make a synthesize request to the server\n",
    "\n",
    "The running server offers a feature for synthesizying a text into a audio. In order to make use of it, the Synthesize method is utilized. This method will receive a SynthesizeRequest and retrieve a SynthesizeResponse.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVdvO-oxUAAR"
   },
   "source": [
    "The following pipelines were chosen to examplify.\n",
    "Linda's voice is choosen for the english voice and Alexandra's voice for german. Therefore, both pipelines need to be asked for to the stab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_pipeline = text_to_speech_pb2.T2sPipelineId(id='linda')\n",
    "english_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SWn5NWOcUBLi"
   },
   "outputs": [],
   "source": [
    "german_pipeline = text_to_speech_pb2.T2sPipelineId(id='alexandra')\n",
    "german_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yENiOXlfUSpg"
   },
   "source": [
    "The example below shows how to synthesize a text into an audio.\n",
    "1.   A configuration has to be created with a RequestConfig, specifying the desired optional parameters.\n",
    "2.   A request has to be created with a SynthesizeRequest, specifying the text to be synthesize and the previously created configuration.\n",
    "3.   By calling the Synthesize method with the created request, the text is synthesized with the specfified configuration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example was created with Alexandra's voice, so as to get an english speaker pronunciation in the audio for the text synthesized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = text_to_speech_pb2.RequestConfig(t2s_pipeline_id=english_pipeline.id)\n",
    "request = text_to_speech_pb2.SynthesizeRequest(text=\"Hi, this is Alexandra. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\", config=config)\n",
    "response = stub.Synthesize(request=request)\n",
    "bio = io.BytesIO(response.audio)\n",
    "audio = sf.read(bio, )\n",
    "ipd.Audio(audio[0], rate=audio[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Length scale configuration\n",
    "The attribute length_scale can be finetuned in order to speed up or slow down the audio. \n",
    "In the next example the length_scale attribute is set to 0.5 so the retrieved audio will be twice as fast as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = text_to_speech_pb2.RequestConfig(t2s_pipeline_id=english_pipeline.id, length_scale = 0.5)\n",
    "request = text_to_speech_pb2.SynthesizeRequest(text=\"Hi, this is Alexandra. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\", config=config)\n",
    "response = stub.Synthesize(request=request)\n",
    "bio = io.BytesIO(response.audio)\n",
    "audio = sf.read(bio, )\n",
    "ipd.Audio(audio[0], rate=audio[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the same attribute is being set to 2.0, therefore, the retrieved audio will be half as fast in comparison to the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-UrYguj_L3dx"
   },
   "outputs": [],
   "source": [
    "config = text_to_speech_pb2.RequestConfig(t2s_pipeline_id=english_pipeline.id, length_scale = 2.0)\n",
    "request = text_to_speech_pb2.SynthesizeRequest(text=\"Hi, this is Alexandra. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\", config=config)\n",
    "response = stub.Synthesize(request=request)\n",
    "bio = io.BytesIO(response.audio)\n",
    "audio = sf.read(bio, )\n",
    "ipd.Audio(audio[0], rate=audio[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Format confguration\n",
    "\n",
    "Another attribute that can be configurated is the audio_format.\n",
    "Audio Format can the setted to:\n",
    "\n",
    "- 0 for wav\n",
    "- 1 for flac\n",
    "- 2 for caf (Core audio format)\n",
    "- 3 for mp3\n",
    "- 4 for acc (Advanced audio coding)\n",
    "- 5 for ogg\n",
    "- 6 for wma (Windows media audio)\n",
    "\n",
    "In the following example, the attribute audio_format is setted to create a wav audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = text_to_speech_pb2.RequestConfig(t2s_pipeline_id=english_pipeline.id, audio_format= 0)\n",
    "request = text_to_speech_pb2.SynthesizeRequest(text=\"Hi, this is Alexandra. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\", config=config)\n",
    "response = stub.Synthesize(request=request)\n",
    "bio = io.BytesIO(response.audio)\n",
    "audio = sf.read(bio, )\n",
    "ipd.Audio(audio[0], rate=audio[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulse Code Modulation\n",
    "\n",
    "The pcm attribute represents the number of pulses created for the audio file.\n",
    "A pcm signal is a sequence of digital audio samples containing the data providing the necessary information to reconstruct the original analog signal.\n",
    "\n",
    "- 0 for 16 (16  bits per sample)\n",
    "- 1 for 24 (24  bits per sample)\n",
    "- 2 for 32 (32  bits per sample)\n",
    "- 3 for S8\n",
    "- 4 for U8\n",
    "- 5 for Float\n",
    "- 6 for Double\n",
    "\n",
    "The number of bit per sample affects the quality and size of the retrieved file. As the number of bits per sample increase, so does the size and quality of the file.\n",
    "\n",
    "In the first example the audio file is generated with the best possible quality and in the second, with the lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = text_to_speech_pb2.RequestConfig(t2s_pipeline_id=english_pipeline.id, pcm=0)\n",
    "request = text_to_speech_pb2.SynthesizeRequest(text=\"Hi, this is Alexandra. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\", config=config)\n",
    "response = stub.Synthesize(request=request)\n",
    "bio = io.BytesIO(response.audio)\n",
    "audio = sf.read(bio, )\n",
    "ipd.Audio(audio[0], rate=audio[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = text_to_speech_pb2.RequestConfig(t2s_pipeline_id=english_pipeline.id, pcm=4)\n",
    "request = text_to_speech_pb2.SynthesizeRequest(text=\"Hi, this is Alexandra. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\", config=config)\n",
    "response = stub.Synthesize(request=request)\n",
    "bio = io.BytesIO(response.audio)\n",
    "audio = sf.read(bio, )\n",
    "ipd.Audio(audio[0], rate=audio[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESk4vzJbMUWy"
   },
   "source": [
    "# Make a synthesize request to the server for a batch of texts\n",
    "\n",
    "The running server offers a feature for synthesizying a batch of texts into audios. In order to make use of it, the BatchSynthesize method is utilized. This method will receive a BatchSynthesizeRequest and retrieve a BatchSynthesizeResponse.\n",
    "\n",
    "The example below shows how to synthesize a batch of texts into a audios.\n",
    "\n",
    "1.   A configuration has to be created with a RequestConfig, specifying the desired optional parameters for each text in the batch.\n",
    "2.   A request has to be created with a SynthesizeRequest, specifying the text to be synthesize and the previously created configuration for each text in the batch with its desired configuration.\n",
    "3.  By calling the BatchSynthesize with the created request, the text is synthesized with the specfified configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V2qYEIZBMoF3"
   },
   "outputs": [],
   "source": [
    "config_1 = text_to_speech_pb2.RequestConfig(t2s_pipeline_id=english_pipeline.id, length_scale = 1.0, pcm=0, audio_format= 0)\n",
    "config_2 = text_to_speech_pb2.RequestConfig(t2s_pipeline_id=german_pipeline.id, length_scale = 1.0, pcm=0, audio_format= 1)\n",
    "config_3 = text_to_speech_pb2.RequestConfig(t2s_pipeline_id=german_pipeline.id, length_scale = 1.0, pcm=1, audio_format= 0)\n",
    "\n",
    "request_1 = text_to_speech_pb2.SynthesizeRequest(text=\"Thank you for your response. We will be waiting you for your appointment with Doctor Smith on Tuesday the first of October at ten in the afternoon.\", config=config_1)\n",
    "request_2 = text_to_speech_pb2.SynthesizeRequest(text=\"Danke f√ºr Ihre Antwort.\", config=config_2)\n",
    "request_3 = text_to_speech_pb2.SynthesizeRequest(text=\"Wir erwarten Sie am Dienstag, den 1. Oktober, um 10 Uhr nachmittags zu Ihrem Termin bei Dr. Smith.\", config=config_3)\n",
    "\n",
    "request = text_to_speech_pb2.BatchSynthesizeRequest(batch_request = [request_1, request_2, request_3])\n",
    "\n",
    "response = stub.BatchSynthesize(request = request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in response.batch_response:\n",
    "    bio = io.BytesIO(message.audio)\n",
    "    audio = sf.read(bio, )\n",
    "    display(ipd.Audio(audio[0], rate=audio[1], autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Pipeline\n",
    "\n",
    "In order to get an specific pipeline configuration the GetT2sPipeline method is used. This method received a T2sPipelineId and retrieves a Text2SpeechConfig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = text_to_speech_pb2.T2sPipelineId(id=german_pipeline.id)\n",
    "pipeline_config = stub.GetT2sPipeline(request=request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkpdKu4O6_b_"
   },
   "source": [
    "## Create Pipeline\n",
    "\n",
    "The server provides a method for creating new pipelines. This can be done with the function CreateT2sPipeline, which receives a Text2SpeechConfig and retrieves a T2sPipelineId."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P4yVorW47Hfd"
   },
   "outputs": [],
   "source": [
    "new_inference_config = pipeline_config.inference\n",
    "new_inference_config.composite_inference.text2mel.glow_tts.length_scale = 2\n",
    "request = text_to_speech_pb2.Text2SpeechConfig(id='alexandra_2.0', description=pipeline_config.description, active=True, inference=new_inference_config, normalization=pipeline_config.normalization, postprocessing=pipeline_config.postprocessing)\n",
    "new_pipeline_id = stub.CreateT2sPipeline(request=request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uV0kSvYYNIfq"
   },
   "source": [
    "## Update Pipeline\n",
    "\n",
    "The server provides a method to update a pipeline called UpdateT2sPipeline, receiving a pipeline configuration.\n",
    "\n",
    "In the following example, the retrieved configuration in the previous call is modified and used to update the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txiSzQnkNPf6"
   },
   "outputs": [],
   "source": [
    "pipeline_config.inference.composite_inference.text2mel.glow_tts.length_scale = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WMVoLpbxNn1I"
   },
   "outputs": [],
   "source": [
    "stub.UpdateT2sPipeline(request=pipeline_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Pipeline\n",
    "\n",
    "A pipeline can be deleted with the method DeleteT2sPipeline, receiving a pipeline id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = text_to_speech_pb2.T2sPipelineId(id='alexandra_2.0')\n",
    "pipeline_config = stub.GetT2sPipeline(request=request)\n",
    "stub.DeleteT2sPipeline(request=request)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ondewo-t2s-with-certificate.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
