{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKWBIVdK_r0Z"
   },
   "source": [
    "## **Text2Speech T2S API**\n",
    "\n",
    "This tutorial uses ondewo-t2s-api to:\n",
    "\n",
    "*   List the possible pipelines that can be used for synthesis\n",
    "*   List the possible languages that can be used in the synthesis process\n",
    "*   List the possible domains\n",
    "*   Synthesize a text to audio\n",
    "*   Synthesize a batch of texts to audios\n",
    "*   Manipulate pipelines (Create, Delete, Update, Get)\n",
    "\n",
    "\n",
    "The first step is to install and the Ondewo Text to Speech client and the requirements needed to interact with the server\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s2ePqjpJccmr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "! pwd\n",
    "! ls\n",
    "! rm -rf ondewo-t2s-client-python\n",
    "! git clone https://github.com/ondewo/ondewo-t2s-client-python.git\n",
    "! cd ondewo-t2s-client-python && git checkout tags/4.0.5 -b 4.0.5 && pip install -r requirements.txt  && git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AZCHNpJytnZ"
   },
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "! cd ondewo-t2s-client-python && python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u05mpboMICjZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import Audio\n",
    "import json\n",
    "from typing import (\n",
    "    Any,\n",
    "    Set,\n",
    "    Tuple,\n",
    ")\n",
    "\n",
    "import grpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqzktvBHdNHN"
   },
   "source": [
    "Afterwards, the client's objects classes need to be imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_l5Y2hqdLO1"
   },
   "outputs": [],
   "source": [
    "\n",
    "from ondewo.t2s.client.client import Client\n",
    "from ondewo.t2s.client.client_config import ClientConfig\n",
    "from ondewo.t2s.text_to_speech_pb2 import ListT2sPipelinesRequest, \\\n",
    "    Text2SpeechConfig\n",
    "from ondewo.t2s.text_to_speech_pb2 import ListT2sLanguagesRequest, \\\n",
    "    ListT2sDomainsRequest\n",
    "from ondewo.t2s.text_to_speech_pb2 import T2sPipelineId, \\\n",
    "    RequestConfig, \\\n",
    "    SynthesizeRequest\n",
    "from ondewo.t2s.text_to_speech_pb2 import BatchSynthesizeRequest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lg990OWCtZRw"
   },
   "source": [
    "## Connect to the Text to Speech Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9Dsp0u7JE-y"
   },
   "source": [
    "The example below shows how to create a secure channel for a text to speech stub object. When setting *use_secure_channel=True*, a grpc certificate *grpc_cert* is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQ4eTNYLJY0W"
   },
   "outputs": [],
   "source": [
    "# credentials = grpc.ssl_channel_credentials(root_certificates=cert)\n",
    "\n",
    "MAX_MESSAGE_LENGTH: int = 60000000\n",
    "GRPC_HOST: str = \"\"\n",
    "GRPC_PORT: str = \"\"\n",
    "CHANNEL: str = f\"{GRPC_HOST}:{GRPC_PORT}\"\n",
    "cert = \"\"\n",
    "use_secure_channel: bool = True if cert else False\n",
    "\n",
    "config: ClientConfig = ClientConfig(host=GRPC_HOST, port=GRPC_PORT, grpc_cert=cert)\n",
    "print(config)\n",
    "\n",
    "# https://github.com/grpc/grpc-proto/blob/master/grpc/service_config/service_config.proto\n",
    "service_config_json: str = json.dumps(\n",
    "    {\n",
    "        \"methodConfig\": [\n",
    "            {\n",
    "                \"name\": [\n",
    "                    # To apply retry to all methods, put [{}] as a value in the \"name\" field\n",
    "                    # {}\n",
    "                    # List single rpc method calls\n",
    "                    {\"service\": \"ondewo.t2s.Text2Speech\", \"method\": \"BatchSynthesize\"},\n",
    "                    {\"service\": \"ondewo.t2s.Text2Speech\", \"method\": \"ListT2sLanguages\"},\n",
    "                    {\"service\": \"ondewo.t2s.Text2Speech\", \"method\": \"ListT2sPipelines\"},\n",
    "                    {\"service\": \"ondewo.t2s.Text2Speech\", \"method\": \"Synthesize\"},\n",
    "                ],\n",
    "                \"retryPolicy\": {\n",
    "                    \"maxAttempts\": 10,\n",
    "                    \"initialBackoff\": \"1.1s\",\n",
    "                    \"maxBackoff\": \"3000s\",\n",
    "                    \"backoffMultiplier\": 2,\n",
    "                    \"retryableStatusCodes\": [\n",
    "                        grpc.StatusCode.CANCELLED.name,\n",
    "                        grpc.StatusCode.UNKNOWN.name,\n",
    "                        grpc.StatusCode.DEADLINE_EXCEEDED.name,\n",
    "                        grpc.StatusCode.NOT_FOUND.name,\n",
    "                        grpc.StatusCode.RESOURCE_EXHAUSTED.name,\n",
    "                        grpc.StatusCode.ABORTED.name,\n",
    "                        grpc.StatusCode.INTERNAL.name,\n",
    "                        grpc.StatusCode.UNAVAILABLE.name,\n",
    "                        grpc.StatusCode.DATA_LOSS.name,\n",
    "                    ],\n",
    "                },\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "options: Set[Tuple[str, Any]] = {\n",
    "    # Define custom max message sizes: 1MB here is an arbitrary example.\n",
    "    (\"grpc.max_send_message_length\", 1024 * 1024),\n",
    "    (\"grpc.max_receive_message_length\", 1024 * 1024),\n",
    "    # Example of setting KeepAlive options through generic channel_args\n",
    "    (\"grpc.keepalive_time_ms\", 2 ** 31 - 1),\n",
    "    (\"grpc.keepalive_timeout_ms\", 20000),\n",
    "    (\"grpc.keepalive_permit_without_calls\", False),\n",
    "    (\"grpc.http2.max_pings_without_data\", 2),\n",
    "    # Example arg requested for the feature\n",
    "    (\"grpc.dns_enable_srv_queries\", 1),\n",
    "    (\"grpc.enable_retries\", 1),\n",
    "    (\"grpc.service_config\", service_config_json)\n",
    "}\n",
    "\n",
    "client: Client = Client(config=config, use_secure_channel=False, options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNqz0BBntZRy"
   },
   "source": [
    "## Get the service information\n",
    "In order to get the service information, the following method can be executed. This will retrieve the release version of the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJwo2mjbtZR0"
   },
   "outputs": [],
   "source": [
    "client.services.text_to_speech.get_service_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kD27LELbJjxg"
   },
   "source": [
    "## List all existing text to speech pipelines\n",
    "\n",
    "All relevant configurations of the text to speech server are defined in a text to speech pipeline. A running server can store several of such configurations at the same time, and the client can choose which one to pick when he/she sends a request to synthesize a text or batch of texts.\n",
    "\n",
    "The example below shows how to list all available pipelines by calling the *ListT2sPipelines* function, which takes a *ListT2sPipelinesRequest* as an argument and retrieves a *ListT2sPipelinesResponse*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MkgvlYO7JmX_"
   },
   "outputs": [],
   "source": [
    "pipelines = client.services.text_to_speech.list_t2s_pipelines(request=ListT2sPipelinesRequest())\n",
    "pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhaYY8x6s18d"
   },
   "source": [
    "## List all possible synthesizying languages\n",
    "\n",
    "A running server can list all possible languages fulfilling specified requirements that can be used to synthesize.\n",
    "\n",
    "The example below shows how to list all available languages by calling the *ListT2sLanguages* function, which takes a *ListT2sLanguagesRequest* as an argument and retrieves a *ListT2sLanguagesResponse*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lN6L5LhitleH"
   },
   "outputs": [],
   "source": [
    "request = ListT2sLanguagesRequest(speaker_sexes=['female'])\n",
    "response = client.services.text_to_speech.list_t2s_languages(request=request)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wk7s6tNvusda"
   },
   "source": [
    "## List all possible domains\n",
    "\n",
    "A running server can list all possible domains fulfilling specified requirements that can be used to synthesize.\n",
    "\n",
    "The example below shows how to list all available domains by calling the *ListT2sDomains* function, which takes a *ListT2sDomainsRequest* as an argument and retrieves a *ListT2sDomainsResponse*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OAv4fX5-vIkl"
   },
   "outputs": [],
   "source": [
    "request = ListT2sDomainsRequest(languages=['en'])\n",
    "response = client.services.text_to_speech.list_t2s_domains(request=request)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kcutwJDLTs-"
   },
   "source": [
    "# Make a synthesize request to the server\n",
    "\n",
    "The running server offers a feature for synthesizing a text into an audio. For that, the Synthesize method is used. This method will receive a SynthesizeRequest and retrieve a SynthesizeResponse.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVdvO-oxUAAR"
   },
   "source": [
    "The following pipelines were chosen to examplify.\n",
    "Brigitte's voice is chosen for the English voice and for German. Therefore, both pipelines need to be asked for to the stub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9V7vPlstZR5"
   },
   "outputs": [],
   "source": [
    "english_pipeline = T2sPipelineId(id='brigitte_en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SWn5NWOcUBLi"
   },
   "outputs": [],
   "source": [
    "german_pipeline = T2sPipelineId(id='brigitte_de')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yENiOXlfUSpg"
   },
   "source": [
    "The example below shows how to synthesize a text into an audio.\n",
    "1.   A configuration has to be created with a *RequestConfig*, specifying the desired optional parameters.\n",
    "2.   A request has to be created with a *SynthesizeRequest*, specifying the text to be synthesized and the previously created configuration.\n",
    "3.   By calling the Synthesize method with the created request, the text is synthesized with the specified configuration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gm_phM3atZR6"
   },
   "source": "The following example was created with Brigitte's voice, so as to get an English speaker pronunciation in the audio for the synthesized text."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uTEIIv8qtZR6"
   },
   "outputs": [],
   "source": [
    "config = RequestConfig(\n",
    "    t2s_pipeline_id=english_pipeline.id,\n",
    "    length_scale=1.0\n",
    ")\n",
    "request = SynthesizeRequest(\n",
    "    text=\"Hi, this is Brigitte. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\",\n",
    "    config=config\n",
    ")\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpL5lStDtZR7"
   },
   "source": [
    "### Length scale configuration\n",
    "The attribute length_scale can be finetuned in order to speed up or slow down the audio.\n",
    "In the next example the length_scale attribute is set to 0.5 so the retrieved audio will be twice as fast as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-jMXjjb3tZR7"
   },
   "outputs": [],
   "source": [
    "config = RequestConfig(\n",
    "    t2s_pipeline_id=english_pipeline.id,\n",
    "    length_scale=0.5\n",
    ")\n",
    "request = SynthesizeRequest(\n",
    "    text=\"Hi, this is Brigitte. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\",\n",
    "    config=config\n",
    ")\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sk8HTDMRtZR7"
   },
   "source": [
    "Next, the same attribute is being set to 2.0, therefore, the retrieved audio will be half as fast in comparison to the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-UrYguj_L3dx"
   },
   "outputs": [],
   "source": [
    "config = RequestConfig(\n",
    "    t2s_pipeline_id=english_pipeline.id,\n",
    "    length_scale=2.0\n",
    ")\n",
    "request = SynthesizeRequest(\n",
    "    text=\"Hi, this is Brigitte. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\",\n",
    "    config=config\n",
    ")\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_015ySStZR8"
   },
   "source": [
    "### Audio Format configuration\n",
    "\n",
    "Another attribute that can be configured is the audio format.\n",
    "The audio format can the set to:\n",
    "\n",
    "- 0 for wav\n",
    "- 1 for flac\n",
    "- 2 for caf (Core audio format)\n",
    "- 3 for mp3\n",
    "- 4 for acc (Advanced audio coding)\n",
    "- 5 for ogg\n",
    "- 6 for wma (Windows media audio)\n",
    "\n",
    "In the following example, the attribute audio_format is set to create a wav audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gquB0QY8tZR8"
   },
   "outputs": [],
   "source": [
    "config = RequestConfig(\n",
    "    t2s_pipeline_id=english_pipeline.id,\n",
    "    audio_format=0\n",
    ")\n",
    "request = SynthesizeRequest(\n",
    "    text=\"Hi, this is Brigitte. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\",\n",
    "    config=config\n",
    ")\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psU228XMtZR8"
   },
   "source": [
    "### Pulse Code Modulation (PCM)\n",
    "\n",
    "The Pulse Code Modulation (PCM) attribute represents the number of pulses created for the audio file.\n",
    "A PCM signal is a sequence of digital audio samples containing the data providing the necessary information to reconstruct the original analog signal.\n",
    "\n",
    "- 0 for 16 (16  bits per sample)\n",
    "- 1 for 24 (24  bits per sample)\n",
    "- 2 for 32 (32  bits per sample)\n",
    "- 3 for S8\n",
    "- 4 for U8\n",
    "- 5 for Float\n",
    "- 6 for Double\n",
    "\n",
    "The number of bits per sample affects the quality and size of the retrieved file. As the number of bits per sample increase, so does the size and quality of the file.\n",
    "\n",
    "In the first example the audio file is generated with the best possible quality and in the second, with the lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6DvuWz35tZR8"
   },
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id, pcm=0)\n",
    "request = SynthesizeRequest(\n",
    "    text=\"Hi, this is Brigitte. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\",\n",
    "    config=config\n",
    ")\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dtdyG5oitZR9"
   },
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id, pcm=4)\n",
    "request = SynthesizeRequest(\n",
    "    text=\"Hi, this is Brigitte. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\",\n",
    "    config=config\n",
    ")\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSML Tags\n",
    "\n",
    "When the service returns a response to a user's request, the user provides text that the ONDEWO text-to-speech service converts to speech. ONDEWO's voices automatically handle normal punctuation, such as pausing after a period.\n",
    "\n",
    "However, in some cases you may want additional control over how the chosen voice generates the speech from the text in your response. For example, you may want the text to be spelled as a code or id, or you may want a string of digits read back as a standard telephone number, email or url. The SSML Tag incorporation provides this type of control over the synthesis process.\n",
    "\n",
    "SSML is a markup language that provides a standard way to mark up text for the generation of synthetic speech. ONDEWO's voices support a subset of the tags defined in the SSML specification. The specific tags supported are: email, phone, URLs, spell and spell-with-names.\n",
    "\n",
    "See how SSML works: https://docs.aws.amazon.com/polly/latest/dg/ssml.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSML Phone Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id)\n",
    "request = SynthesizeRequest(\n",
    "    text='Hi, this is Brigitte. Thanks for calling. I am not here at the moment, so please leave a message to the following number <say-as interpret-as=\"phone\">+12354321</say-as>and I will call you back.',\n",
    "    config=config\n",
    ")\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSML Email Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id)\n",
    "request = SynthesizeRequest(\n",
    "    text='Hi, this is Brigitte. Thanks for calling. I am not here at the moment, so please send an email to the following address <say-as interpret-as=\"email\">voices@ondewo.com.at</say-as>',\n",
    "    config=config\n",
    ")\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSML Url Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id)\n",
    "request = SynthesizeRequest(\n",
    "    text='Hi, this is Brigitte. Thanks for calling. I am not here at the moment, so please visit the site <say-as interpret-as=\"url\">ondewo.com/en/</say-as>',\n",
    "    config=config\n",
    ")\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSML Spell Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id)\n",
    "request = SynthesizeRequest(\n",
    "    text='My reservation number is <say-as interpret-as=\"spell\">AP732</say-as>',\n",
    "    config=config\n",
    ")\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSML Spell With Names Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id)\n",
    "request = SynthesizeRequest(\n",
    "    text='My reservation number is <say-as interpret-as=\"spell-with-names\">AHO32</say-as>',\n",
    "    config=config\n",
    ")\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSML Callsigns Short Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id)\n",
    "request = SynthesizeRequest(\n",
    "    text='I am going to Frankfurt in the flight <say-as interpret-as=\"callsign-short\">AUA439</say-as>',\n",
    "    config=config\n",
    ")\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSML Callsigns Long Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id)\n",
    "request = SynthesizeRequest(\n",
    "    text='I am going to Frankfurt in the flight <say-as interpret-as=\"callsign-long\">AAL439</say-as>',\n",
    "    config=config\n",
    ")\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSML Break Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id)\n",
    "request = SynthesizeRequest(\n",
    "    text='I am going to take a 2 seconds break <break time=\"2.0\"/> done',\n",
    "    config=config\n",
    ")\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arphabet Phonemes\n",
    "\n",
    "Most languages, including English, can be described in terms of a set of distinctive sounds, or phonemes. In particular, for American English, there are about 42 phonemes including vowels, diphthongs, semi-vowels and consonants.\n",
    "\n",
    "The standard international method to represent phonemes is the International Phonetic Alphabet (IPA). To enable computer representation of the phonemes, it is convenient to code them as ASCII characters and we can do this with the ARPABET scheme.\n",
    "\n",
    "For example:\n",
    "\n",
    "- Bee : {B IY1}\n",
    "- She : {SH IY1}\n",
    "- Red : {R EH1 D}\n",
    "- Sofa : {S OW1 F AH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id)\n",
    "request = SynthesizeRequest(\n",
    "    text='Hello I am {AE2 L EH0 G Z AE1 N D R AH0}',\n",
    "    config=config\n",
    ")\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdfCmhBSAGOm"
   },
   "source": [
    "# Make a synthesize request to the server for a batch of texts\n",
    "\n",
    "The running server offers a feature for synthesizying a batch of texts into audios. For that, the BatchSynthesize method is used. This method will receive a BatchSynthesizeRequest and retrieve a BatchSynthesizeResponse.\n",
    "\n",
    "The example below shows how to synthesize a batch of texts into audios.\n",
    "\n",
    "1.   A configuration has to be created with a RequestConfig, specifying the desired optional parameters for each text in the batch.\n",
    "2.   A request has to be created with a SynthesizeRequest, specifying the text to be synthesized and the previously created configuration for each text in the batch with its desired configuration.\n",
    "3.  By calling the BatchSynthesize with the created request, the text is synthesized with the specified configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3erqBYpALJ9"
   },
   "source": [
    "The following pipelines were chosen to examplify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5B1wLqTAUuu"
   },
   "outputs": [],
   "source": [
    "config_1 = RequestConfig(t2s_pipeline_id=english_pipeline.id, length_scale=1.0, pcm=0, audio_format=0)\n",
    "config_2 = RequestConfig(t2s_pipeline_id=english_pipeline.id, length_scale=0.5, pcm=0, audio_format=1)\n",
    "config_3 = RequestConfig(t2s_pipeline_id=german_pipeline.id, length_scale=1.0, pcm=1, audio_format=0)\n",
    "\n",
    "request_1 = SynthesizeRequest(text='Hello', config=config_1)\n",
    "request_2 = SynthesizeRequest(text='How are you?', config=config_2)\n",
    "request_3 = SynthesizeRequest(text='Hallo, wie geht es dir?', config=config_3)\n",
    "\n",
    "request = BatchSynthesizeRequest(batch_request=[request_1, request_2, request_3])\n",
    "\n",
    "response = client.services.text_to_speech.batch_synthesize(request=request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktULf2b0DiGk"
   },
   "outputs": [],
   "source": [
    "for audio_message in response.batch_response:\n",
    "    display(Audio(audio_message.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7-VTdUrtZSF"
   },
   "source": [
    "## Get Pipeline\n",
    "\n",
    "In order to get a specific pipeline configuration, the GetT2sPipeline method is used. This method received a T2sPipelineId and retrieves a Text2SpeechConfig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "to73X70rtZSF"
   },
   "outputs": [],
   "source": [
    "request = T2sPipelineId(id=german_pipeline.id)\n",
    "pipeline_config = client.services.text_to_speech.get_t2s_pipeline(request=request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkpdKu4O6_b_"
   },
   "source": [
    "## Create Pipeline\n",
    "\n",
    "The server provides a method for creating new pipelines. This can be done with the function CreateT2sPipeline, which receives a Text2SpeechConfig and retrieves a T2sPipelineId."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P4yVorW47Hfd"
   },
   "outputs": [],
   "source": [
    "new_inference_config = pipeline_config.inference\n",
    "new_inference_config.composite_inference.text2mel.glow_tts.length_scale = 2\n",
    "request = Text2SpeechConfig(\n",
    "    id='brigitte2.0',  # Pipeline Id\n",
    "    description=pipeline_config.description,  # Pipeline Description\n",
    "    active=True,  # Pipeline is active or not\n",
    "    inference=new_inference_config,  # Pipeline Inference configuration\n",
    "    normalization=pipeline_config.normalization,  # Pipeline Normalization Parameters\n",
    "    postprocessing=pipeline_config.postprocessing\n",
    ")  # Pipeline Postprocessing\n",
    "new_pipeline_id = client.services.text_to_speech.create_t2s_pipeline(request=request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uV0kSvYYNIfq"
   },
   "source": [
    "## Update Pipeline\n",
    "\n",
    "The server provides a method to update a pipeline called UpdateT2sPipeline, receiving a pipeline configuration.\n",
    "\n",
    "In the following example, the retrieved configuration in the previous call is modified and used to update the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txiSzQnkNPf6"
   },
   "outputs": [],
   "source": [
    "pipeline_config.inference.composite_inference.text2mel.glow_tts.length_scale = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WMVoLpbxNn1I"
   },
   "outputs": [],
   "source": [
    "client.services.text_to_speech.update_t2s_pipeline(request=pipeline_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FP4Hsy9ctZSG"
   },
   "source": [
    "## Delete Pipeline\n",
    "\n",
    "A pipeline can be deleted with the method DeleteT2sPipeline, receiving a pipeline id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5XH8ArwBtZSG"
   },
   "outputs": [],
   "source": [
    "request = T2sPipelineId(id='brigitte2.0')\n",
    "pipeline_config = client.services.text_to_speech.get_t2s_pipeline(request=request)\n",
    "client.services.text_to_speech.delete_t2s_pipeline(request=request)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ondewo_t2s_with_certificate.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
